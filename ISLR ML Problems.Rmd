---
title: "ISLR ML Problems"
author: "Robbie Mc Guinness"
date: "12/11/2021"
output: github_document
---


# Chapter 2: Statistical Learning

### Question 8
```{r}
library(ISLR)
summary(College)
pairs(College[,2:6])
boxplot(College$Outstate~College$Private)
Elite<-rep("No",nrow(College))
Elite[College$Top10perc>50]<-"Yes"
Elite<-as.factor(Elite)
College<-data.frame(College,Elite)
summary(College$Elite)
boxplot(College$Outstate~College$Elite)
par(mfrow=c(2,2))
hist(College$Room.Board,breaks=25)
hist(College$Books,breaks=15)
hist(College$Apps,breaks=50)
hist(College$PhD,breaks=12)

```
  

### Question 9
  The variables Name and Origin are qualitative and the rest are quantitative.
  
```{r}
for (i in 1:7)
{cat("The range of", names(Auto)[i],"is",range(Auto[,i]),"\n")}
```
  
```{r}
for (i in 1:7)
{cat("The mean and standard deviation of",names(Auto)[i],"are",mean(Auto[,i]),"and",sd(Auto[,i]),"\n")}
```


```{r}
Auto2<-Auto[-c(10:85),]
for (i in 1:7)
{cat("Having removed the 10th through 85th rows; the range of", names(Auto2)[i],"is",range(Auto2[,i]),"\n and the mean and standard deviation of",names(Auto2)[i],"are",mean(Auto2[,i]),"and",sd(Auto2[,i]),".\n")}
```

```{r}
pairs(Auto[,1:7])
```

There appears to be strong positive linear relationships between horsepower and weight. Similarly, there is a positive approximately linear relationship between horsepower and displacement and between weight and displacement.

The predictors displacement, weight and horsepower seem to be the ones with the most obvious relationship to mpg. Each exhibits a decreasing weakly non-linear relationship with mpg.

### Question 10
   
```{r}
library(ISLR2)
cat("The number of rows in the Boston dataset is",nrow(Boston),".")

cat("The number of columns in the Boston dataset is",ncol(Boston),".")
```
The rows represent different suburbs of Boston and the columns represent various housing and area statistics for each suburb. 

```{r}
pairs(Boston[,1:6])
pairs(Boston[,7:13])
```

```{r}
par(mfrow=c(3,4))
for (i in 2:13)
{plot(Boston$crim,Boston[,i],ylab=names(Boston)[i])}
```

None of the predictors seem to have a correlation with the per capita crime rate

```{r}
par(mfrow=c(3,1))
hist(Boston$crim,breaks=30)
hist(Boston$tax,breaks=30)
hist(Boston$ptratio,breaks=30)
```

From the histograms it is clear to see that there is a small number of outliers that have very large crime rates. Similarly, there are a number of suburbs where property tax is appreacibly above all other suburbs. The pupil teacher ratio is reasonably uniform apart from one large peak just above 20. 

```{r}
cat("The number of suburbs bordering the Charles river is",sum(Boston$chas),"\n")

cat("The median pupil teacher ratio is",median(Boston$ptratio))

cat("The minimum median value of owner occupied homes is",min(Boston$medv),"and it occurs in the",which.min(Boston$medv),"suburb.\n")

medians<-rep(0,ncol(Boston))
for (i in 1:ncol(Boston))
{if (median(Boston[,i])==0)
     {medians[i]=mean(Boston[,i])}
else
{medians[i]=median(Boston[,i])}
cat("The",names(Boston)[i], "predictor value at this location is",round(Boston[which.min(Boston$medv),i]/medians[i],3),"times the median value of that predictor. \n")}

room7<-rep(0,nrow(Boston))
room7[Boston$rm>7]=1
cat("The number of suburbs that average more than 7 rooms per house is",sum(room7)," representing",round(sum(room7)/length(room7),3),"of suburbs  \n")

room8<-rep(0,nrow(Boston))
room8[Boston$rm>8]=1
cat("The number of suburbs that average more than 8 rooms per house is",sum(room8)," representing",round(sum(room8)/length(room8),3),"of suburbs  \n")
```

# Chapter 3: Linear Regression

## Question 8


```{r}
Auto.fit1<-lm(mpg~horsepower,data=Auto)
summary(Auto.fit1)
predict(Auto.fit1,data.frame(horsepower=(98)),interval="confidence")
predict(Auto.fit1,data.frame(horsepower=(98)),interval="prediction")
```

There is a negative relationship between mpg and horsepower. For each unit increase in horsepower the mpg decreases by `coef(Auto.fit1)[2]`. The confidence and prediction intervals for a horsepower of 98 are as given above.

```{r}
plot(Auto$horsepower,Auto$mpg)
abline(Auto.fit1)
par(mfrow=c(2,2))
plot(Auto.fit1)
```

# Chapter 4: Classification

# Chapter 5: Resampling Methods

# Chapter 6: Linear Model Selection and Regularisation

# Chapter 7: Moving Beyond Linearity

# Chapter 8: Tree Based Methods

# Chapter 9: Support Vector Machines

# Chapter 10: Deep Learning

# Chapter 11: Survival Analysis and Censored Data

# Chapter 12: Unsupervised Learning

# Chapter 13: Multiple Testing

